# jobbole_article
伯乐在线scrapy-redis+docker分布式爬虫

# 需求分析
爬取某技术博客中所有的文章, 实现分布式并保存数据到mysql中.
# 难点
爬虫代理地址的使用, 由于免费代理的速度和质量都无法保证, 这里使用付费代理. 付费代理一般都有过期时间的限制, 并且可能会被目标网站设置为黑名单, 所以需要解决代理的过期和服务器的拒绝这两个问题. 
这里代理地址使用的方法是每次从代理api获取一个代理地址, 一个爬虫节点上只使用这一个代理直到它过期或被网站封禁, 然后再切换代理. 并且实现了简单高效的方法来判断代理的过期或网站的封禁, 以及解决了多个请求的代理同时过期, 同时向代理api请求获取代理地址的问题.
# 效果
经测试, 2个api代理地址足够5个爬虫节点使用, 可以扩展到10-20个节点. 1.2W个网页耗用的代理数量在20-30个.
